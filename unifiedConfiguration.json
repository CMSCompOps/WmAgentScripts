{
 "email_destination" : { 
   "value" : ["vlimant@cern.ch","matteoc@fnal.gov","areinsvo@nd.edu","thong@caltech.edu"],
   "description" : "The list of people that get the emails notifications"
 },
 "site_out_of_overflow": {
   "value" : ["T1_UK_RAL","T1_IT_CNAF"],
   "description" : "The sites that shoudl be taken out completely from the overflow mapping"
 },
 "site_for_overflow": {
   "value" : ["T2_CH_CERN_HLT",
   	     "nonono_T0_CH_CERN"],
   "description" : "The sites that we set to overflow and require a specific treatment"
 },
 "overflow_pressure": {
   "value" : 0.5,
   "description" : "The ratio pending/running over which to consider overflowing"
 },
 "PU_overflow_overflow_reco":{
   "value" : false,
   "descrition" : "Whether or not to overflow the second step (reco) for workfow with PU_overflow enabled"
 },
 "mem_quanta": {
    "value" : 1000,
    "description" : "The quanta of memory in MB for the JobRouter"
 },
 "time_quanta": {
    "value" : 50,
    "description" : "The quanta of time in min for the JobRouter"
 },
 "slope_quanta": {
    "value" : 250,
    "description" : "The quanta of the slope of memory/core in MB for the JobRouter"
 },
 "read_quanta": {
    "value" : 100,
    "description" : "The quanta of read requirements in kb/something for the JobRouter"
 },
 "htcondor_binning": {
    "value" : 5,
    "description" : "The number of bins to use for quantizing values used for tuning job requirements"
 },
 "DDM_buffer_level": {
   "value" : 0.8,
   "description" : "The fraction of the DDM quota we are allowed to use"
 },
 "sites_banned": {
   "value" : ["T2_CH_CERN_AI",
	      "T2_TH_CUNSTDA",
	      "T2_EE_Estonia",
	      "T2_UA_KIPT",
	      "NONO_T0_CH_CERN"
 	      ],
   "description" : "The sites that are banned from production"
 },		 
 "sites_auto_approve": {
   "value" : ["T0_CH_CERN_MSS","T1_FR_CCIN2P3_MSS"],
   "description" : "The sites we can autoapprove tape request to"
 },
 "sites_space_override": {	
   "value" : { 
      	     "T0_CH_CERN_Disk" : 0
	       },
   "description" : "Over-ride the available space at a phedex end point"
 },
 "sites_with_goodIO": {
    "value" : ["T2_DE_DESY","T2_DE_RWTH","T2_ES_CIEMAT","T2_FR_GRIF_LLR", "T2_FR_GRIF_IRFU", "T2_FR_IPHC","T2_FR_CCIN2P3","T2_IT_Bari", "T2_IT_Legnaro", "T2_IT_Pisa", "T2_IT_Rome","T2_UK_London_Brunel", "T2_UK_London_IC","T2_US_Caltech","T2_US_MIT","T2_US_Nebraska","T2_US_Purdue","T2_US_UCSD","T2_US_Wisconsin","T2_US_Florida","T2_BE_IIHE","T2_EE_Estonia","T2_PL_Swierk","T2_CH_CERN","T2_CH_CERN_HLT"],
    "description" : "The sites identified as having good storage badnwidth"
 },
 "blow_up_limits" : {
   "value" : [5,10],
   "description" : "Pair of Blow up factor for taskchain above which to act, and needed amount of cores to receive large such taskchain. Probably deprecated now with GQ taking this into account. Was (5,4000) before"
 },
 "GB_space_limit" : {
   "value" : 20,
   "description" : "The value in GB that we allow the output size to be before adapting the splitting"
 },
  "output_size_correction": {
   "value" : { "Phase" : 1 },
   "description" : "The correction factor to be applied to SizePerEvent per keyword."
 },
 "memory_correction": {
   "value" : { "PhaseIITDRFall17DR" : 18000 },
   "description" : "The memory setting to be set for task with that keyword in"
 },
 "max_cpuh_block" : {
   "value" : 40000000,
   "description" : "Value of CPUh above which a wf is blocked from assigning"
 },
 "block_repositionning": {
   "value" : true,
   "description" : "Whether or not to retransfer block from WQE without location"
 },
 "allowed_bypass": {
   "description" : "Who is allowed to bypass and force complete",
   "value" : [
              ["vlimant","vlimant@cern.ch"],
   	      ["prozober","paola.katherine.rozo.bernal@cern.ch"],
	      ["mcremone","matteoc@fnal.gov"],
              ["qnguyen","thong@caltech.edu"]
             ]
 },
 "max_tail_priority" : {
   "value" : 5,
   "description" : "Number of workflow to increase the priority of at a time"
 },
 "injection_delay_threshold" : {
   "value" : 50,
   "description" : "Number of days after wich to increase the priority of a workflow"
 },  
 "delay_priority_increase" : {
   "value" : 10000,
   "description" : "Priority from original increase per week over the delay threshold"
 },
 "injection_delay_priority" : {
   "value" : 75000,
   "description" : "Priority above which we can increase the priority of a workflow after running too long"
 },
 
 "max_force_complete" : {
   "value" : 20,
   "description" : "Number of workflow that can be forced complete at a time"
 },
 "max_per_round" : {
   "description" : "limitation on the number of wf to process per module",
   "value" : {
    "transferor" : null,
    "assignor" : null,
    "closor" : null,
    "checkor" : null,
    "completor" : null
    }
 },
 "default_fraction_overdoing" :{
   "value" : 1.05,
   "description" : "Completion fraction above which a workflow will force complete"
 },
 "default_fraction_pass" : {
   "value" : 1.0,
   "description" : "completion fraction above which to announce dataset"
 },
 "pattern_fraction_pass": {
   "value" : { },
   "description" : "overide of the completion fraction of dataset with keyword"
 },
 "tiers_with_no_custodial": {
   "value" : ["DQM","DQMIO","RECO","RAWAODSIM"],
   "description": "The data tiers that do not go to tape. Can be overidden by custodial overide at campaign level"
 },
 "use_parent_custodial": {
   "value" : false,
   "description": "Use the location of the parent dataset for custodial copy"
 },
 "tape_size_limit" : {
   "value" : 200,
   "description" : "Size over which to prevent transfer to tape automatically"
 },
 "tiers_with_no_check": {
   "value" : ["DQM","DQMIO"],
   "description": "The data tiers that do not pass closeout checks. Can be overidden by custodial overide at campaign level"
 },
 "tiers_no_DDM": {
   "value" : ["GEN-SIM","LHE","GEN","DQM","DQMIO","GEN-SIM-DIGI-RAW","RAW"],
   "description": "The data tiers that do not go to AnaOps"
 },
 "tiers_to_DDM": {
   "value" : ["AODSIM","MINIAODSIM","GEN-SIM-RAW","GEN-SIM-RECO","GEN-SIM-RECODEBUG","AOD","RECO","MINIAOD","ALCARECO","USER","RAW-RECO","RAWAODSIM"],
   "description": "The data tiers that go to AnaOps"
 },
 "secondary_lock_timeout": {
   "value" : 30,
   "description": "The number of days to keep a secondary input locked"
 },
 "tiers_keep_on_disk": {
   "value" : ["LHE"],
   "description": "the data tier not unlocked until used again"
 },
 "check_fullcopy_to_announce": {
  "value" : false,
  "description": "Whether to check for a full copy being present prior to announcing a dataset"
 },
 "stagor_sends_back": {
   "value" : true,
   "description": "Whether the stagor module can send workflow back to considered"
 },
  "max_handled_workflows": {
   "value" : 4000,
   "description": "The total number of workflows that we allow to handle at a time (transfer, running, assistance)"
  },
  "max_staging_workflows": {
   "value" : 700,
   "description": "The total number of workflows that we allow to stage at a time"
  }, 
  "max_staging_workflows_per_site": {
   "value" : 700,
   "description": "The total number of workflows that we allow to stage at a time per site"
  },
  "max_transfer_in_GB": {
   "value" : 800000,
   "description": "The total size of the input datasets that can be transfered at a given time"
  },
  "transfer_timeout": {
   "value" : 7,
   "description": "Time in days after which to consider a transfer to be stuck"
  },
  "transfer_lowrate": {
   "value" : 0.004,
   "description": "Rate in GB/s under which to consider a transfer to be stuck, after transfer_timeout days"
  },
  "less_copies_than_requested": {
   "value" : 1,
   "description": "Decrease the number of requested copies by that number, floored to 1"
  },
  "chopping_threshold_in_GB": {
  "value" : 4000,
  "description": "The threshold before choping an input dataset in chunk of that size for spreading to sites"
  },
  "retrieve_errors_timeout": {
    "value" : 10,
    "description" : "Time in minute that we allow to get logs from where they are before shutting retrieval down."
  },
  "full_report_top_N":{
    "value" : 10,
    "description" : "The number of top N workflows with failures and cooloff to show."
  },
  "expose_top_N":{
    "value" : 3,
    "description" :"The number of top N error code to expose logs of."
  },
  "n_error_exposed":{
    "value" : 0,
    "description" :"The default number of job cmsrun logs to retrieve"
  },
  "expose_archive_code":{
    "value" : [134,139,99109,99303,60450,50513,50660,8001,8002,8004,8026,11003,73,74,87],
    "description" : "The error codes that should get a cmsrun log exposed"
  },
  "expose_condor_code":{
    "value" : [99109,99303,60450,61202,50513,50660,11003],
    "description" :  "The error codes that should get a condor lot exposed."
  },
  "use_recoveror":{
    "value" : false,
    "description" : "Whethe automatic recovery can be tried."
  },
  "error_codes_to_recover": {
  "value" : { "50664" : [ { "legend" : "time-out",
  	           "solution" : "split-2" ,
                   "details" : null,
                   "rate" : 20 
                  } ],
        "50660" : [ { "legend" : "memory excess",
                  "solution" : "mem-+1000" ,
                  "details" : null,
                  "rate" : 20
                  } ],
        "61104" : [ { "legend" : "failed submit",
                  "solution" : "recover" ,
                  "details" : null,
                  "rate" : 20 
                  } ],
        "8028" : [ { "legend" : "read error",
                 "solution" : "recover" ,
                 "details" : null,
                 "rate" : 20 
                 } ],
        "8021" : [ { "legend" : "cmssw failure",
                 "solution" : "recover" , 
                 "details" : "FileReadError",
                 "rate" : 20
                 } ],
        "71305" : [ { "legend" : "long pending",
                 "solution" : "recover" , 
                 "details" : null,
                 "rate" : 20
                 } ],
        "8001" : [ { "legend" : "lhe failure",
                 "solution" : "split-4" , 
                 "details" : "No lhe event found in ExternalLHEProducer::produce()",
                 "rate" : 20
                 } ]
        },
  "description" : "The error code, threshold and rules for auto-recovery"
  },
  "error_codes_to_block" : {
  "value" : 
      {
        "99109" : [{ "legend" : "stage-out",
                   "solution" : "recover",
                   "details" : null,
                   "rate" : 20
                   }]
    },
  "description" : "The error code, threshold and rules to prevent auto-recovery"
  },
  "error_codes_to_notify" : {
  "value" : {
   "8021" : { "message" : "Please take a look and come back to Ops." }
  },
  "description" : "The error code, threshold and rules to notify the user of an error in production"
  },
  "user_rereco":{
   "description" : "The users from which we expect ReReco requests",
   "value" : ["cerminar","fabozzi","prebello","amaltaro"]
  },
  "user_relval":{
   "description" : "The users from which we expect relval requests",
   "value" : ["fabozzi","nwickram","bsutar","rverma","prebello","piperov","sandhya","zhenhu","muahmad"]
  },
  "relval_routing":{
   "description" : "Set of keywords and special settings for relvals",
   "value" : { "cc7" : { "parameters" : { "SiteWhitelist" : ["T2_US_Nebraska"]}},
   	       "highPU" : {"parameters" : { "SiteWhitelist" : ["T2_US_Nebraska","T2_US_Purdue"]}},
	       "highIO" : {"parameters" : { "SiteWhitelist" : ["T2_US_Nebraska","T2_US_Purdue"]}},
	       "ALCA_" : { "primary_AAA" : true , 
	       	       	   "parameters" : { "SiteWhitelist" : ["T1_US_FNAL"]}
			},
	 	"NANO_" : { "parameters" : { "MaxMergeSize" : 100 ,"MinMergeSize": 50, "LumisPerJob" : 1000 }}
             }
  },
  "batch_goodness":{
   "description" : "Level below which to include a note in the batch report",
   "value" : 90
  }
}
